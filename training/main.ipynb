{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!pip install opencv-python-headless\n",
    "!pip install albumentations\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [chr(i) for i in range(ord('A'), ord('Z') + 1)] + [str(i) for i in range(10)]\n",
    "class_map = {c: idx for idx, c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert kaggle dataset to YOLO format\n",
    "kaggle_base_dir = './raw_data/kaggle_dataset'\n",
    "kaggle_base_dir2 = './raw_data/kaggle_dataset2'\n",
    "output_dir = './raw_data/yolo_format'\n",
    "output_dir2 = './raw_data/yolo_format2'\n",
    "def convert_to_yolo_format(kaggle_base_dir, output_dir):\n",
    "    for class_label, class_index in class_map.items():\n",
    "        folder_path = os.path.join(kaggle_base_dir, class_label)\n",
    "        for image_file in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            x_center, y_center, box_width, box_height = 0.5, 0.5, 1.0, 1.0\n",
    "\n",
    "            label_path = os.path.join(output_dir, f\"{os.path.splitext(image_file)[0]}.txt\")\n",
    "            with open(label_path, \"w\") as f:\n",
    "                f.write(f\"{class_index} {x_center} {y_center} {box_width} {box_height}\")\n",
    "            \n",
    "            cv2.imwrite(os.path.join(output_dir, image_file), image)\n",
    "\n",
    "convert_to_yolo_format(kaggle_base_dir, output_dir)\n",
    "convert_to_yolo_format(kaggle_base_dir2, output_dir2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset_dir = './datasets'\n",
    "os.makedirs(combined_dataset_dir, exist_ok=True)\n",
    "for subset in ['train', 'test', 'valid']:\n",
    "    os.makedirs(os.path.join(combined_dataset_dir, subset, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(combined_dataset_dir, subset, 'labels'), exist_ok=True)\n",
    "\n",
    "roboflow_base_dir = './raw_data/robo_dataset'\n",
    "roboflow_train_dir = os.path.join(roboflow_base_dir, 'train')\n",
    "roboflow_test_dir = os.path.join(roboflow_base_dir, 'test')\n",
    "roboflow_valid_dir = os.path.join(roboflow_base_dir, 'valid')\n",
    "\n",
    "def copy_dataset(src_dir, dest_dir):\n",
    "    for file_type in ['images', 'labels']:\n",
    "        src_folder = os.path.join(src_dir, file_type)\n",
    "        dest_folder = os.path.join(dest_dir, file_type)\n",
    "        for file_name in os.listdir(src_folder):\n",
    "            src_file = os.path.join(src_folder, file_name)\n",
    "            dest_file = os.path.join(dest_folder, file_name)\n",
    "            shutil.copy(src_file, dest_file)\n",
    "\n",
    "copy_dataset(roboflow_train_dir, os.path.join(combined_dataset_dir, 'train'))\n",
    "copy_dataset(roboflow_test_dir, os.path.join(combined_dataset_dir, 'test'))\n",
    "copy_dataset(roboflow_valid_dir, os.path.join(combined_dataset_dir, 'valid'))\n",
    "\n",
    "kaggle_yolo_dir2 = './raw_data/yolo_format' # Change this to kaggle formated dataset\n",
    "kaggle_yolo_dir = './raw_data/yolo_format2' # Change this to kaggle formated dataset\n",
    "\n",
    "def copy_kaggle_dataset(dest_dir):\n",
    "    all_kaggle_images = [f for f in os.listdir(dest_dir) if f.endswith('.jpg')]\n",
    "    random.shuffle(all_kaggle_images)\n",
    "    train_split = int(0.8 * len(all_kaggle_images))\n",
    "    valid_split = int(0.9 * len(all_kaggle_images))\n",
    "\n",
    "    kaggle_splits = {\n",
    "        'train': all_kaggle_images[:train_split],\n",
    "        'valid': all_kaggle_images[train_split:valid_split],\n",
    "        'test': all_kaggle_images[valid_split:]\n",
    "    }\n",
    "\n",
    "    for subset, images in kaggle_splits.items():\n",
    "        for image_name in images:\n",
    "            src_image = os.path.join(dest_dir, image_name)\n",
    "            dest_image = os.path.join(combined_dataset_dir, subset, 'images', image_name)\n",
    "            shutil.copy(src_image, dest_image)\n",
    "            \n",
    "            label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "            src_label = os.path.join(dest_dir, label_name)\n",
    "            dest_label = os.path.join(combined_dataset_dir, subset, 'labels', label_name)\n",
    "            if os.path.exists(src_label):\n",
    "                shutil.copy(src_label, dest_label)\n",
    "\n",
    "copy_kaggle_dataset(kaggle_yolo_dir)\n",
    "copy_kaggle_dataset(kaggle_yolo_dir2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import albumentations as A\n",
    "\n",
    "# Define augmentations\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=45, p=0.5), \n",
    "    A.RGBShift(r_shift_limit=40, g_shift_limit=40, b_shift_limit=40, p=.2),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.35,p=.5),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.2),\n",
    "        A.MedianBlur(blur_limit=3, p=0.2),\n",
    "        A.Blur(blur_limit=3, p=0.2)\n",
    "    ]),\n",
    "], bbox_params=A.BboxParams(format='yolo', min_visibility=0.4))\n",
    "\n",
    "# Function to load, augment, and save images\n",
    "def augment_and_save_image(image_path, label_path, output_dir, augmentations_per_image=5):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return\n",
    "\n",
    "    with open(label_path, 'r') as file:\n",
    "        bboxes = []\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            bbox = list(map(float, parts[1:]))\n",
    "            bboxes.append([*bbox, class_id])\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    img_output_dir = os.path.join(output_dir, 'images')\n",
    "    lbl_output_dir = os.path.join(output_dir, 'labels')\n",
    "    os.makedirs(img_output_dir, exist_ok=True)\n",
    "    os.makedirs(lbl_output_dir, exist_ok=True)\n",
    "\n",
    "    # Generate augmented images and labels\n",
    "    for i in range(augmentations_per_image):\n",
    "        augmented = augmentation_pipeline(image=image, bboxes=bboxes)\n",
    "\n",
    "        aug_image = augmented['image']\n",
    "        aug_image_filename = f\"{os.path.spliteaut_dir, aug_image_filename)\n",
    "        cv2.imwrite(aug_image_path, aug_image)\n",
    "\n",
    "        aug_label_filename = f\"{os.path.splitext(os.path.basename(label_path))[0]}_aug_{i}.txt\"\n",
    "        aug_label_path = os.path.join(lbl_output_dir, aug_label_filename)\n",
    "        with open(aug_label_path, 'w') as file:\n",
    "            for bbox in augmented['bboxes']:\n",
    "                class_id = int(bbox[4])\n",
    "                bbox_str = ' '.join(map(str, bbox[:4]))\n",
    "                file.write(f\"{class_id} {bbox_str}\\n\")\n",
    "\n",
    "dataset_dir = './datasets' # Change this to your dataset directory\n",
    "output_dir = './augmented' # Change this to your output directory\n",
    "\n",
    "for subset in ['train', 'test', 'valid']:\n",
    "    image_dir = os.path.join(dataset_dir, subset, 'images')\n",
    "    label_dir = os.path.join(dataset_dir, subset, 'labels')\n",
    "\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        label_path = os.path.join(label_dir, os.path.splitext(image_file)[0] + '.txt')\n",
    "        if os.path.exists(label_path):\n",
    "            augment_and_save_image(image_path, label_path, os.path.join(output_dir, subset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "results = model.train(data=\"./data.yaml\", epochs=300, imgsz=640, save_period=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If needed to pause and resume\n",
    "model = YOLO(\"./runs/detect/train3/weights/last.pt\") # Last trained model\n",
    "results = model.train(data=\"./data.yaml\", epochs=300, imgsz=640, save_period=20, resume=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
